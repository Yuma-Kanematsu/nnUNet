{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "36860ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f4a8eee4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:  58%|█████▊    | 302/518 [00:12<00:08, 24.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: No ROI detected in 6951166_25_R_MED-3_0000.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images: 100%|██████████| 518/518 [00:20<00:00, 25.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing Summary:\n",
      "Total images processed: 518\n",
      "ROI successfully detected: 517 (99.81%)\n",
      "ROI detection failed: 1 (0.19%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Constants\n",
    "TARGET_SIZE = 512  # Output image size\n",
    "\n",
    "def remove_padding_and_resize(img, target_size=TARGET_SIZE):\n",
    "    \"\"\"画像のリサイズと中央配置を行う関数\n",
    "    \n",
    "    与えられた画像をアスペクト比を維持しながら指定サイズにリサイズし、\n",
    "    黒色の背景の中央に配置します。\n",
    "    \n",
    "    Args:\n",
    "        img: 入力画像（numpy配列）\n",
    "        target_size: 出力画像の目標サイズ（デフォルト値：TARGET_SIZE）\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (処理後の画像, (x開始位置, y開始位置, スケール))\n",
    "            - 処理後の画像: target_size × target_sizeの正方形画像\n",
    "            - x開始位置: リサイズ後の画像の配置開始x座標\n",
    "            - y開始位置: リサイズ後の画像の配置開始y座標\n",
    "            - スケール: 元画像に対する縮小/拡大率\n",
    "    \"\"\"\n",
    "    # 入力画像が3チャンネルでない場合（マスク画像など）、適切に処理\n",
    "    is_grayscale = len(img.shape) == 2\n",
    "    \n",
    "    h, w = img.shape[:2]\n",
    "    scale = target_size / max(h, w)\n",
    "    new_w = int(w * scale)\n",
    "    new_h = int(h * scale)\n",
    "    \n",
    "    # グレースケール画像とカラー画像でリサイズ方法を分ける\n",
    "    if is_grayscale:\n",
    "        resized = cv2.resize(img, (new_w, new_h), interpolation=cv2.INTER_NEAREST)\n",
    "        final_img = np.zeros((target_size, target_size), dtype=img.dtype)\n",
    "    else:\n",
    "        resized = cv2.resize(img, (new_w, new_h), interpolation=cv2.INTER_AREA)\n",
    "        final_img = np.zeros((target_size, target_size, 3), dtype=img.dtype)\n",
    "    \n",
    "    start_x = (target_size - new_w) // 2\n",
    "    start_y = (target_size - new_h) // 2\n",
    "    \n",
    "    if is_grayscale:\n",
    "        final_img[start_y:start_y+new_h, start_x:start_x+new_w] = resized\n",
    "    else:\n",
    "        final_img[start_y:start_y+new_h, start_x:start_x+new_w] = resized\n",
    "    \n",
    "    return final_img, (start_x, start_y, scale)\n",
    "\n",
    "def process_dataset(model_path, input_dir, output_dir, conf_threshold=0.9):\n",
    "    \"\"\"CT画像とセグメンテーションマスクを処理するメイン関数\n",
    "    \n",
    "    Args:\n",
    "        model_path: YOLOモデルのパス\n",
    "        input_dir: 入力データセットディレクトリ\n",
    "        output_dir: 出力ディレクトリ\n",
    "        conf_threshold: 検出信頼度の閾値（デフォルト：0.25）\n",
    "    \"\"\"\n",
    "    # 入力ディレクトリのパス\n",
    "    images_dir = os.path.join(input_dir, \"imagesTr\") # ここを場合に応じてimagesTrなどに変更\n",
    "    labels_dir = os.path.join(input_dir, \"labelsTr\")\n",
    "    \n",
    "    # 出力ディレクトリの作成\n",
    "    output_images_dir = os.path.join(output_dir, \"imagesTr\")\n",
    "    output_labels_dir = os.path.join(output_dir, \"labelsTr\")\n",
    "    \n",
    "    os.makedirs(output_images_dir, exist_ok=True)\n",
    "    os.makedirs(output_labels_dir, exist_ok=True)\n",
    "    \n",
    "    # YOLOモデルのロード\n",
    "    model = YOLO(model_path)\n",
    "    \n",
    "    # 画像ファイルの一覧を取得\n",
    "    image_files = [f for f in os.listdir(images_dir) if f.endswith('.png')]\n",
    "    \n",
    "    successful_crops = 0\n",
    "    failed_crops = 0\n",
    "    \n",
    "    for img_file in tqdm(image_files, desc=\"Processing images\"):\n",
    "        img_path = os.path.join(images_dir, img_file)\n",
    "        \n",
    "        # 画像の読み込み\n",
    "        img = cv2.imread(img_path)\n",
    "        if img is None:\n",
    "            print(f\"Warning: Could not read image {img_path}\")\n",
    "            continue\n",
    "            \n",
    "        # 対応するマスクファイル名を取得\n",
    "        # 例: 6375522_20_R_FLOOR-3_0000.png → 6375522_20_R_FLOOR-3.png\n",
    "        mask_file = img_file.rsplit('_', 1)[0] + '.png'\n",
    "        mask_path = os.path.join(labels_dir, mask_file)\n",
    "        \n",
    "        # マスクが存在するか確認\n",
    "        if not os.path.exists(mask_path):\n",
    "            print(f\"Warning: Mask file not found: {mask_path}\")\n",
    "            continue\n",
    "            \n",
    "        # マスクの読み込み\n",
    "        mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "        if mask is None:\n",
    "            print(f\"Warning: Could not read mask {mask_path}\")\n",
    "            continue\n",
    "        \n",
    "        # YOLOでROIを検出\n",
    "        results = model.predict(\n",
    "            source=img,\n",
    "            conf=conf_threshold,\n",
    "            verbose=False\n",
    "        )\n",
    "        \n",
    "        roi_detected = False\n",
    "        \n",
    "        for result in results:\n",
    "            boxes = result.boxes\n",
    "            if len(boxes) > 0:\n",
    "                # 最も確信度の高いROIを使用\n",
    "                best_box = boxes[boxes.conf.argmax()]\n",
    "                roi_detected = True\n",
    "                \n",
    "                # ROIの座標を取得\n",
    "                x1, y1, x2, y2 = map(int, best_box.xyxy.cpu().numpy()[0])\n",
    "                \n",
    "                # 画像とマスクからROIをクロップ\n",
    "                cropped_img = img[y1:y2, x1:x2]\n",
    "                cropped_mask = mask[y1:y2, x1:x2]\n",
    "                \n",
    "                # カラー画像をグレースケールに変換\n",
    "                cropped_img = cv2.cvtColor(cropped_img, cv2.COLOR_BGR2GRAY)\n",
    "                \n",
    "                # クロップした画像とマスクをリサイズして中央配置\n",
    "                processed_img, _ = remove_padding_and_resize(cropped_img, target_size=TARGET_SIZE)\n",
    "                processed_mask, _ = remove_padding_and_resize(cropped_mask, target_size=TARGET_SIZE)\n",
    "                \n",
    "                # 画像とマスクを保存\n",
    "                cv2.imwrite(os.path.join(output_images_dir, img_file), processed_img)\n",
    "                cv2.imwrite(os.path.join(output_labels_dir, mask_file), processed_mask)\n",
    "                \n",
    "                successful_crops += 1\n",
    "                break  # 最も確信度の高いROIのみを処理\n",
    "        \n",
    "        if not roi_detected:\n",
    "            print(f\"Warning: No ROI detected in {img_file}\")\n",
    "            failed_crops += 1\n",
    "    \n",
    "    # 処理結果の統計を表示\n",
    "    total_images = len(image_files)\n",
    "    print(f\"\\nProcessing Summary:\")\n",
    "    print(f\"Total images processed: {total_images}\")\n",
    "    print(f\"ROI successfully detected: {successful_crops} ({successful_crops/total_images*100:.2f}%)\")\n",
    "    print(f\"ROI detection failed: {failed_crops} ({failed_crops/total_images*100:.2f}%)\")\n",
    "\n",
    "# メイン実行部分\n",
    "if __name__ == \"__main__\":\n",
    "    # パスの設定\n",
    "    INPUT_DIR = \"/Users/yuma/Yuma-Kanematsu/nnUNet/src/raw_data/Dataset006_Orbital_Trap_All\"\n",
    "    OUTPUT_DIR = \"/Users/yuma/Yuma-Kanematsu/nnUNet/src/raw_data/Dataset007_Orbital_Trap_All_ROI\"\n",
    "    MODEL_PATH = \"/Users/yuma/Yuma-Kanematsu/nnUNet/src/yolov8n_ROI_241108.pt\"  # YOLOモデルのパスを指定\n",
    "    \n",
    "    # メイン処理を実行\n",
    "    process_dataset(MODEL_PATH, INPUT_DIR, OUTPUT_DIR, conf_threshold=0.9)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
